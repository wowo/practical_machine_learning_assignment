---
title: "Classification of weight lifting correctness based on Human Activity Recognition"
author: "Wojciech Sznapka"
date: "21.11.2014"
output:
  html_document:
    fig_caption: yes
    highlight: tango
---

## Introduction

The prompt is to predict quality of human's activity based on measurements collected from several sensors located on different parts of body. Six participants were performing Unilateral Dumbbell Biceps excercies, while wearing sensors and being assessed by experienced weight lifter. They were doing excercises in five different manners, described as classes A, B, C, D, E. The classes mean following:

* A - correct execution of excercise
* B - throwing the elbows to the front 
* C - lifting the dumbbell only halfway
* D - lowering the dumbbell only halfway
* E - throwing the hips to the front.

The figure below ilustrates number and locations of sensors.

![On body sensing schema](on-body-sensing-schema.png)

Figure 1. On-body sensing schema.


## Loading Data

Two datasets (training and test) were downloaded from <http://coursera.org> website, from **Practical Machine Learning** class resources on 21.11.2014. The training data for this project are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>. The test data are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>. The original source of the data is located here: <http://groupware.les.inf.puc-rio.br/har>

Whole data processing were done using R software (R version 3.0.2 (2013-09-25)) under 32-bit Ubuntu Linux. Caret, randomForest and mlearning packages were used.

```{r}
library(caret)
library(randomForest)
```

The data was loaded from CSV and preeliminary examined to figure out it's size and specification.

```{r}
train <- read.csv(file = 'pml-training.csv');
finalTest <- read.csv(file = 'pml-testing.csv');
```

```{r}
dim(train)
```

Testing data were missing **classe** (A/B/C/D/E) variable and the prompt was to predict it. So we decided to build model on subset of training data and validate it on rest of it. The model was splited 0.75 / 0.25.

```{r}
partition <- createDataPartition(train$classe, p=.75, list=F)
trainPC <- train[partition,]
testPC <- train[-partition,]
```

Exploatory analysis of the data showed that some columns doesn't play significant role in model building. Thus we decided to drop them for further processing.

```{r}
drops <- c('X', 'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp', 'new_window', 'num_window')
trainPC <- trainPC[, !(names(trainPC) %in% drops)]
testPC <- testPC[, !(names(testPC) %in% drops)]
finalTest <- finalTest[, !(names(finalTest) %in% drops)]
```

What's more, we decided to remove another set of columns, which were returned by near zero var method

```{r}
colsToDrop <- nearZeroVar(trainPC)
dim(colsToDrop)

trainPC <- trainPC[, -colsToDrop]
testPC <- testPC[, -colsToDrop]
finalTest <- finalTest[, -colsToDrop]
```

The last step of data preparation was dealing with NA values. Some columns were very sparse, meaning they contained a lot of NA's. That caused inability to predict values for those columns. We fixed that situation by putting zeros instead of NA's

```{r}
trainPC[is.na(trainPC)] <- 0
testPC[is.na(testPC)] <- 0
finalTest[is.na(finalTest)] <- 0
```

## Building Model

We decided to use Random Forest classification algorithm to build model which will be used for predicting. The model was build on training data and validated on testig data. Then it was used to solve actual problem - predict 20 activities in provided test set. The usage of caret 's train method was impossible due to problems with memory. Calling randomForest method directly made significant improvement in performace. Model was build based on **classe** variable and all remaining features.

```{r}
modFit <- randomForest(classe ~ ., data=trainPC)
```

We can see which variables played significant role in prediction bu using `varImpPlot` which plots dotchart of variable importance as measured by a Random Forest .

```{r}
varImpPlot(modFit)
```

Figure 2. Variables importance 

We can see that belt, dumbbell and forearm give important measurements, while arm isn't that important here.

## Analysis

Using previously created model, we predicted values on training and test sets. The results proved that usage of Random Forest were right choice to make. We used `confusion` and `confusionImage` to visualise Confusion Matrix, to check how model performs and how many mistakes it produces.

```{r}
library(mlearning)
```
```{r}
predTrain <- predict(modFit, trainPC)
confusionImage(confusion(predTrain, trainPC$classe))
```

Figure 3. Confussion matrix for train data


```{r}
predTest <- predict(modFit, testPC)
confusionImage(confusion(predTest, testPC$classe))
```

Figure 4. Confussion matrix for test data

We can see that model's accuracy for extracted test set is 99% which is very good score. Random forest algorithm performs very well on default parameters, giving very high accuracy. The bespoken model has been used for test set provided for automatical grading.

```{r}
finalTest$prediction <- predict(modFit, finalTest)
```

Predicted values for given test has been uploaded to Coursera platform for automatic grading. All 20 samples were predicted correctly, which proved that we build right model.

## References
[1] Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

[2] Random Forest on Wikipedia <http://en.wikipedia.org/wiki/Random_forest>
